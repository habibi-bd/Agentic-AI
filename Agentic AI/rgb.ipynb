{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "039ff4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw array shape: (2, 2, 3)\n",
      "Raw values:\n",
      " [[[255   0   0]\n",
      "  [  0 255   0]]\n",
      "\n",
      " [[  0   0 255]\n",
      "  [255 255   0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adnan Habib\\AppData\\Local\\Temp\\ipykernel_12796\\2458747707.py:11: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  img = Image.fromarray(data, 'RGB')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Make a simple 2x2 RGB image\n",
    "data = np.array([\n",
    "    [[255, 0, 0], [0, 255, 0]],   # Red, Green\n",
    "    [[0, 0, 255], [255, 255, 0]]  # Blue, Yellow\n",
    "], dtype=np.uint8)\n",
    "\n",
    "\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "img.show()\n",
    "\n",
    "print(\"Raw array shape:\", data.shape)\n",
    "print(\"Raw values:\\n\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0645bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw array shape: (3, 3, 3)\n",
      "Raw values:\n",
      " [[[255   0   0]\n",
      "  [  0 255   0]\n",
      "  [  0   0 255]]\n",
      "\n",
      " [[255 255   0]\n",
      "  [  0 255 255]\n",
      "  [255   0 255]]\n",
      "\n",
      " [[128 128 128]\n",
      "  [255 255 255]\n",
      "  [  0   0   0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adnan Habib\\AppData\\Local\\Temp\\ipykernel_12796\\1976312741.py:11: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  img = Image.fromarray(data, 'RGB')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Create a 3x3 RGB image\n",
    "data = np.array([\n",
    "    [[255, 0, 0],   [0, 255, 0],   [0, 0, 255]],    # Red, Green, Blue\n",
    "    [[255, 255, 0], [0, 255, 255], [255, 0, 255]],  # Yellow, Cyan, Magenta\n",
    "    [[128, 128, 128], [255, 255, 255], [0, 0, 0]]   # Gray, White, Black\n",
    "], dtype=np.uint8)\n",
    "\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "img.show()\n",
    "\n",
    "print(\"Raw array shape:\", data.shape)\n",
    "print(\"Raw values:\\n\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3461902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Convert to tensor (PyTorch uses CHW: Channels, Height, Width)\n",
    "to_tensor = T.ToTensor()\n",
    "tensor_img = to_tensor(img)\n",
    "\n",
    "print(\"Tensor shape:\", tensor_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0484c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "Image size (width, height): (32, 32)\n",
      "Shape of array (H, W, C): (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "img=Image.open('emoji.png')\n",
    "# img.show()\n",
    "img= img.resize((32,32))\n",
    "\n",
    "print(img.size)\n",
    "img_array = np.array(img)\n",
    "print(\"Image size (width, height):\", img.size)\n",
    "print(\"Shape of array (H, W, C):\", img_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8027082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"RGB matrix:\\n\", img_array[30])\n",
    "# for i in range(30, 40):\n",
    "#     print(img_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "154d11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToTensor()\n",
    "img_tensor = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d9e681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape (B, C, H, W): torch.Size([1, 3, 32, 32])\n",
      "Tensor values:\n",
      " tensor([[[[0.3882, 0.3882, 0.3882,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          [0.3882, 0.3882, 0.3882,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          [0.3882, 0.3882, 0.3882,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          ...,\n",
      "          [0.3882, 0.3882, 0.3804,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          [0.3882, 0.3882, 0.3882,  ..., 0.3882, 0.3882, 0.3882],\n",
      "          [0.3882, 0.3882, 0.3882,  ..., 0.3882, 0.3882, 0.3882]],\n",
      "\n",
      "         [[0.5882, 0.5882, 0.5882,  ..., 0.5882, 0.5882, 0.5882],\n",
      "          [0.5882, 0.5882, 0.5882,  ..., 0.5882, 0.5882, 0.5882],\n",
      "          [0.5882, 0.5882, 0.5882,  ..., 0.5882, 0.5882, 0.5882],\n",
      "          ...,\n",
      "          [0.5882, 0.5882, 0.5922,  ..., 0.5882, 0.5882, 0.5882],\n",
      "          [0.5882, 0.5882, 0.5882,  ..., 0.5882, 0.5882, 0.5882],\n",
      "          [0.5882, 0.5882, 0.5882,  ..., 0.5882, 0.5882, 0.5882]],\n",
      "\n",
      "         [[0.9255, 0.9255, 0.9255,  ..., 0.9255, 0.9255, 0.9255],\n",
      "          [0.9255, 0.9255, 0.9255,  ..., 0.9255, 0.9255, 0.9255],\n",
      "          [0.9255, 0.9255, 0.9255,  ..., 0.9255, 0.9255, 0.9255],\n",
      "          ...,\n",
      "          [0.9255, 0.9255, 0.9333,  ..., 0.9255, 0.9255, 0.9255],\n",
      "          [0.9255, 0.9255, 0.9255,  ..., 0.9255, 0.9255, 0.9255],\n",
      "          [0.9255, 0.9255, 0.9255,  ..., 0.9255, 0.9255, 0.9255]]]])\n"
     ]
    }
   ],
   "source": [
    "img_tensor= img_tensor.unsqueeze(0)  # Add batch dimension\n",
    "print(\"Tensor shape (B, C, H, W):\", img_tensor.shape)\n",
    "print(\"Tensor values:\\n\", img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b1599bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60c430d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3050fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af7bc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after Conv2d: torch.Size([1, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "output = conv1(img_tensor)\n",
    "print(\"Output shape after Conv2d:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94e7ddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "90837361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1912, -1.0700,  1.2381,  1.0358, -0.3722, -0.3079,  0.0822,\n",
      "           0.9230],\n",
      "         [-1.4085,  0.2772,  0.3883, -1.3357, -0.7279,  0.3466, -0.2030,\n",
      "          -0.1040],\n",
      "         [-0.3655, -1.6868,  0.2347,  2.1797,  0.0920,  1.3699, -1.6303,\n",
      "          -1.6722],\n",
      "         [-0.4250,  0.4998, -1.4255, -0.6987,  1.9643,  0.5322,  0.6776,\n",
      "          -0.1829]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 4,8)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d7a1d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8])\n",
      "torch.Size([1, 4, 24])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.shape)\n",
    "qkv = nn.Linear(8, 24)(x) \n",
    "print(qkv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1f6549fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5684,  0.2852,  0.1358, -0.0923,  0.2989,  0.0778, -1.1424,\n",
      "           0.5875],\n",
      "         [ 0.9549, -0.1833,  1.1566, -0.3844,  0.0771,  0.1366,  0.3882,\n",
      "          -1.2462],\n",
      "         [ 0.5960, -0.8793,  0.9915, -0.0793,  0.7765,  0.3699, -1.0047,\n",
      "          -0.6748],\n",
      "         [ 0.4899,  0.3007, -0.1053, -0.2095,  0.7283,  0.3676,  0.0085,\n",
      "          -0.8186]]], grad_fn=<SliceBackward0>)\n",
      "tensor([-0.5684,  0.2852,  0.1358, -0.0923,  0.2989,  0.0778, -1.1424,  0.5875,\n",
      "         0.0876,  0.0060, -0.3071,  0.3287,  0.2057,  0.3588,  0.5383,  0.0356,\n",
      "        -0.4341, -0.6153, -0.1719, -0.2440,  0.2368,  0.6945, -1.3581,  0.5539],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Q=qkv[:, :, :8]\n",
    "K=qkv[:, :, 8:16]\n",
    "V=qkv[:, :, 16:]\n",
    "print(Q)\n",
    "print(qkv[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e4f88cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: [[1 2]\n",
      " [3 4]]\n",
      "After Linear layer: tensor([[-0.4864, -1.3765, -0.3872, -2.0773],\n",
      "        [-1.5242, -2.6500, -0.5154, -3.5167]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1, 2], [3, 4]])\n",
    "print(\"Original array:\", array)\n",
    "qkv = nn.Linear(2, 4)(torch.tensor(array, dtype=torch.float32))\n",
    "print(\"After Linear layer:\", qkv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e8ece22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0876,  0.0060, -0.3071,  0.3287,  0.2057,  0.3588,  0.5383,\n",
       "           0.0356],\n",
       "         [-0.9506,  0.7599, -0.4849, -0.3653, -0.1188,  0.0494, -0.7666,\n",
       "          -0.5839],\n",
       "         [-0.7219,  2.2370,  0.4613,  0.1493, -0.0865, -0.3448, -0.0866,\n",
       "           1.0914],\n",
       "         [-0.4587,  0.2832, -0.7233, -0.3588, -0.0075, -0.8209, -0.9163,\n",
       "          -0.8578]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d4c458a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0876, -0.9506, -0.7219, -0.4587],\n",
       "         [ 0.0060,  0.7599,  2.2370,  0.2832],\n",
       "         [-0.3071, -0.4849,  0.4613, -0.7233],\n",
       "         [ 0.3287, -0.3653,  0.1493, -0.3588],\n",
       "         [ 0.2057, -0.1188, -0.0865, -0.0075],\n",
       "         [ 0.3588,  0.0494, -0.3448, -0.8209],\n",
       "         [ 0.5383, -0.7666, -0.0866, -0.9163],\n",
       "         [ 0.0356, -0.5839,  1.0914, -0.8578]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.transpose(-2, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
